{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Lab 8\n",
    "#### Programmed By Sravanth Chowdary Poturi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implantation of CNN using PyTorch Tutorial for Image classification.1. Load and normalize any dataset available in PyTorch\n",
    "2. Design LeNet model using PyTorch.\n",
    "3. Train and Test the model on the selected dataset\n",
    "4. Experiment with different number of filters, kernel sizes, number of layers.\n",
    "5. Compare the results.\n",
    "\n",
    "Reference Link:[Click Here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# load and normalize the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# define the classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Design LeNet model using PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train and Test the model on the selected dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net()\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# train the model\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# test the model on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "# print the accuracy\n",
    "print('The Accuracy is' % (\n",
    "    100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Experiment with different number of filters, kernel sizes, number of layers.\n",
    "# Compare the results.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# setting the parameters to be used as list\n",
    "filters = [6, 12, 18, 24]\n",
    "kernel_sizes = [3, 5, 7, 9]\n",
    "layers = [2, 3, 4, 5]\n",
    "\n",
    "# dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# loop over the parameters\n",
    "for filter in filters:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        for layer in layers:\n",
    "            # define the model\n",
    "            class Net(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super(Net, self).__init__()\n",
    "                    self.conv1 = nn.Conv2d(3, filter, kernel_size)\n",
    "                    self.pool = nn.MaxPool2d(2, 2)\n",
    "                    self.conv2 = nn.Conv2d(filter, 16, kernel_size)\n",
    "                    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "                    self.fc2 = nn.Linear(120, 84)\n",
    "                    self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "                def forward(self, x):\n",
    "                    x = self.pool(F.relu(self.conv1(x)))\n",
    "                    x = self.pool(F.relu(self.conv2(x)))\n",
    "                    x = x.view(-1, 16 * 5 * 5)\n",
    "                    x = F.relu(self.fc1(x))\n",
    "                    x = F.relu(self.fc2(x))\n",
    "                    x = self.fc3(x)\n",
    "                    return x\n",
    "\n",
    "                def num_flat_features(self, x):\n",
    "                    size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "                    num_features = 1\n",
    "                    for s in size:\n",
    "                        num_features *= s\n",
    "                    return num_features\n",
    "\n",
    "            # define the loss function and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "            # train the model\n",
    "            for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "                running_loss = 0.0\n",
    "                for i, data in enumerate(trainloader, 0):\n",
    "                    # get the inputs\n",
    "                    inputs, labels = data\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # print statistics\n",
    "                    running_loss += loss.item()\n",
    "                    if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                        print('[%d, %5d] loss: %.3f' %\n",
    "                              (epoch + 1, i + 1, running_loss / 2000))\n",
    "                        running_loss = 0.0\n",
    "\n",
    "            print('Finished Training')\n",
    "            # save the results\n",
    "            results[(filter, kernel_size, layer)] = (100 * correct / total)\n",
    "\n",
    "# plot the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x = np.array([i[0] for i in results.keys()])\n",
    "y = np.array([i[1] for i in results.keys()])\n",
    "z = np.array([i[2] for i in results.keys()])\n",
    "c = np.array([i for i in results.values()])\n",
    "ax.scatter(x, y, z, c=c)\n",
    "ax.set_xlabel('Number of Filters')\n",
    "ax.set_ylabel('Kernel Size')\n",
    "ax.set_zlabel('Number of Layers')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}